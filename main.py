import os
import re  # ç”¨ä¾†åšæ­£è¦è¡¨é”å¼åˆ¤æ–· (Regex)
from dotenv import load_dotenv

# æ–°å¢é€™å€‹ï¼šGoogle åŸç”Ÿ SDK (ç”¨ä¾†ä¸Šå‚³æª”æ¡ˆ)
import google.generativeai as genai
import yt_dlp  # ç”¨ä¾†ä¸‹è¼‰ YouTube éŸ³è»Œ

# --- 1. åˆå§‹åŒ–ç’°å¢ƒèˆ‡ API Key ---
load_dotenv()
my_api_key = os.environ.get("MY_GEMINI_KEY")
if not my_api_key:
    print("âŒ éŒ¯èª¤ï¼šæ‰¾ä¸åˆ° MY_GEMINI_KEY")
    exit(1)

# ã€æ–°å¢ã€‘ï¼šè¨­å®š Google GenAI SDK
genai.configure(api_key=my_api_key)

# --- 2. åŒ¯å…¥å¿…è¦çš„ LangChain èˆ‡å·¥å…·åº« ---
from typing import Optional, List, Dict, Any
from typing_extensions import TypedDict

from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser

# ç¶²é èˆ‡ YouTube è¼‰å…¥å™¨
from langchain_community.document_loaders import WebBaseLoader
from langchain_community.document_loaders import YoutubeLoader

from langchain_core.messages import HumanMessage  # æ–°å¢é€™å€‹ï¼šç”¨ä¾†å»ºæ§‹å¤šæ¨¡æ…‹è¨Šæ¯

# LangGraph å…ƒä»¶
from langgraph.graph import StateGraph, END


# --- 3. å®šç¾©ç‹€æ…‹ (State) ---
# é€™æ˜¯æˆ‘å€‘ V1 ç‰ˆæœ¬çš„è³‡æ–™çµæ§‹ï¼Œæ‰€æœ‰ç¯€é»éƒ½åªæœƒè®€å¯«é€™å€‹å­—å…¸
class OmniState(TypedDict):
    input_text: str  # ä½¿ç”¨è€…æœ€åŸå§‹çš„è¼¸å…¥ (ç¶²å€æˆ–æ–‡å­—)
    source_type: str  # åˆ¤æ–·çµæœï¼š'youtube', 'web', 'text'
    content: Optional[str]  # æŠ“å–ä¸¦æ¸…æ´—å¾Œçš„ã€Œç´”æ–‡å­—ã€å…§å®¹
    summary: Optional[str]  # æœ€çµ‚ç”Ÿæˆçš„æ‘˜è¦
    error: Optional[str]  # å¦‚æœä¸­é–“å‡ºéŒ¯ï¼Œè¨˜éŒ„éŒ¯èª¤è¨Šæ¯
    file_obj: Any  # å­˜æ”¾ä¸Šå‚³å¾Œçš„æª”æ¡ˆç‰©ä»¶ (å¦‚æœæ˜¯éŸ³è¨Šè™•ç†çš„è©±)


# --- 4. è¼”åŠ©å‡½å¼ï¼šåˆ¤æ–·è¼¸å…¥é¡å‹ ---
def detect_source_type(input_text: str) -> str:
    """
    ç°¡å–®çš„è¦å‰‡åˆ¤æ–·ï¼š
    1. åŒ…å« youtube.com æˆ– youtu.be -> 'youtube'
    2. åŒ…å« http:// æˆ– https:// -> 'web'
    3. å…¶ä»– -> 'text'
    """
    text = input_text.strip().lower()
    if "youtube.com" in text or "youtu.be" in text:
        return "youtube"
    elif text.startswith("http://") or text.startswith("https://"):
        return "web"
    else:
        return "text"


# --- 5. ç¯€é» (Node)ï¼šè·¯ç”±å™¨ (åˆ†æè¼¸å…¥) ---
def analyze_input_node(state: OmniState) -> Dict[str, Any]:
    print("\n--- [ç¯€é» 1] åˆ†æè¼¸å…¥é¡å‹ ---")
    user_input = state["input_text"]
    source_type = detect_source_type(user_input)

    print(f"åµæ¸¬çµæœ: {source_type}")
    # å›å‚³æ›´æ–° state
    return {"source_type": source_type}


# --- 6. ç¯€é» (Node)ï¼šYouTube è¼‰å…¥å™¨ ---
def load_youtube_node(state: OmniState) -> Dict[str, Any]:
    print("\n--- [ç¯€é» 2-A] è™•ç† YouTube ---")
    url = state["input_text"]

    try:
        print("1. å˜—è©¦ä¸‹è¼‰å­—å¹•...")
        # å„ªå…ˆæ‰¾ä¸­æ–‡ï¼Œç„¶å¾Œè‹±æ–‡ï¼Œæ¥è‘—æ˜¯æ—¥éŸ“æ³•å¾·è¥¿ä¿„ç­‰å¸¸è¦‹èªè¨€
        common_languages = [
            "zh-Hant",
            "zh-TW",
            "zh-Hans",
            "zh",
            "zh-HK",
            "en",
            "ja",
            "ko",
            "es",
            "fr",
            "de",
            "it",
            "pt",
            "ru",
        ]

        loader = YoutubeLoader.from_youtube_url(
            url, add_video_info=False, language=common_languages
        )
        docs = loader.load()

        if docs:
            transcript = docs[0].page_content
            print(f"âœ… æˆåŠŸæŠ“å–å­—å¹•ï¼Œé•·åº¦: {len(transcript)} å­—")
            return {
                "content": f"ã€å½±ç‰‡å­—å¹•ã€‘ï¼š\n{transcript}",
                "file_obj": None,
                "error": None,
            }

    except Exception as e:
        print(f"âš ï¸ å­—å¹•æŠ“å–å¤±æ•— (å°‡å˜—è©¦ Plan B): {e}")

    # === Plan B: ä¸‹è¼‰éŸ³è¨Šä¸¦ã€Œè½ã€å…§å®¹ ===
    print("2. å•Ÿå‹• Plan Bï¼šä¸‹è¼‰éŸ³è¨Š (Gemini è½åŠ›æ¨¡å¼)...")

    # è¨­å®šä¸‹è¼‰æª”å (æš«å­˜)
    temp_audio_file = "temp_audio.m4a"

    # yt-dlp è¨­å®šï¼šåªä¸‹è¼‰æœ€å¥½çš„éŸ³è¨Šï¼Œä¸¦å­˜æˆ m4a
    ydl_opts = {
        "format": "bestaudio[ext=m4a]/best[ext=mp4]/best",
        "outtmpl": temp_audio_file,
        "quiet": True,
        "noplaylist": True,
    }

    try:
        # 1. ä¸‹è¼‰éŸ³è¨Š
        with yt_dlp.YoutubeDL(ydl_opts) as ydl:
            ydl.download([url])
        print(f"âœ… éŸ³è¨Šä¸‹è¼‰å®Œæˆ: {temp_audio_file}")

        # 2. ä¸Šå‚³åˆ° Gemini
        print("3. æ­£åœ¨ä¸Šå‚³éŸ³è¨Šåˆ° Google Gemini...")
        audio_file = genai.upload_file(path=temp_audio_file)
        print(f"âœ… ä¸Šå‚³æˆåŠŸï¼ŒFile URI: {audio_file.uri}")

        # 3. åˆªé™¤æœ¬åœ°æš«å­˜æª” (ä¿æŒç’°å¢ƒä¹¾æ·¨)
        if os.path.exists(temp_audio_file):
            os.remove(temp_audio_file)

        # å›å‚³ file_obj è®“ä¸‹ä¸€å€‹ç¯€é»ä½¿ç”¨
        return {"content": None, "file_obj": audio_file, "error": None}

    except Exception as e:
        print(f"âŒ Plan B å¤±æ•—: {e}")
        return {
            "error": f"YouTube å­—å¹•èˆ‡éŸ³è¨Šçš†å¤±æ•—: {str(e)}",
            "content": None,
            "file_obj": None,
        }


# --- 7. ç¯€é» (Node)ï¼šç¶²é è¼‰å…¥å™¨ ---
def load_web_node(state: OmniState) -> Dict[str, Any]:
    print("\n--- [ç¯€é» 2-B] è™•ç†ç¶²é  ---")
    url = state["input_text"]

    try:
        # ä½¿ç”¨ WebBaseLoader æŠ“å–ç¶²é 
        loader = WebBaseLoader(url)
        docs = loader.load()

        if not docs:
            return {"error": "ç¶²é æŠ“å–ç‚ºç©º", "content": None}

        # ç°¡å–®æ¸…æ´—ï¼šå»é™¤å¤šé¤˜æ›è¡Œ
        raw_content = docs[0].page_content
        clean_content = re.sub(r"\n\s*\n", "\n\n", raw_content)  # æŠŠå¤šå€‹ç©ºè¡Œè®Šæˆä¸€å€‹

        print(f"æˆåŠŸæŠ“å–ç¶²é ï¼Œé•·åº¦: {len(clean_content)} å­—")
        return {"content": clean_content, "error": None}

    except Exception as e:
        print(f"ç¶²é è¼‰å…¥å¤±æ•—: {e}")
        return {"error": f"ç¶²é è™•ç†å¤±æ•—: {str(e)}", "content": None}


# --- 8. ç¯€é» (Node)ï¼šç´”æ–‡å­—è™•ç† (é€å‚³) ---
def load_text_node(state: OmniState) -> Dict[str, Any]:
    print("\n--- [ç¯€é» 2-C] è™•ç†ç´”æ–‡å­— ---")
    # å¦‚æœä½¿ç”¨è€…ç›´æ¥è²¼æ–‡ç« ï¼Œå°±ç›´æ¥ç•¶ä½œ content
    return {"content": state["input_text"], "error": None}


# --- 9. ç¯€é» (Node)ï¼šæ‘˜è¦ç”Ÿæˆå™¨ (AI å¤§è…¦) ---
def generate_summary_node(state: OmniState) -> Dict[str, Any]:
    print("\n--- [ç¯€é» 3] AI æ­£åœ¨æ’°å¯«æ‘˜è¦ ---")

    # 1. æª¢æŸ¥å‰ä¸€æ­¥é©Ÿæ˜¯å¦æœ‰éŒ¯èª¤
    if state.get("error"):
        print("åµæ¸¬åˆ°å‰ä¸€æ­¥é©ŸéŒ¯èª¤ï¼Œè·³éç”Ÿæˆã€‚")
        return {"summary": f"ç„¡æ³•ç”Ÿæˆæ‘˜è¦ï¼ŒåŸå› ï¼š{state['error']}"}

    # 2. åˆå§‹åŒ– Gemini
    # æ³¨æ„ï¼šé€™è£¡ä¸€å®šè¦å‚³å…¥ google_api_key
    llm = ChatGoogleGenerativeAI(
        model="gemini-2.5-flash-lite", google_api_key=my_api_key
    )

    # 3. è¨­å®šæç¤ºè© (Prompt)
    # æˆ‘å€‘æ˜ç¢ºè¦æ±‚ï¼šä¸ç®¡åŸæ–‡æ˜¯ä»€éº¼ï¼Œéƒ½è¦ç”¨ç¹é«”ä¸­æ–‡å›ç­”
    system_prompt = (
        "ä½ æ˜¯ä¸€ä½å…¨èƒ½çš„è³‡è¨Šæ•´ç†å°ˆå®¶ã€‚è«‹é–±è®€ä»¥ä¸‹å…§å®¹ï¼ˆä¾†æºï¼š{source_type}ï¼‰ï¼Œ"
        "ä¸¦ç‚ºæˆ‘æ’°å¯«ä¸€ä»½ã€Œæ‡¶äººåŒ…æ‘˜è¦ã€ã€‚"
        "\n\n"
        "ã€è¦æ±‚ã€‘ï¼š\n"
        "1. **èªè¨€**ï¼šç„¡è«–åŸæ–‡æ˜¯å“ªåœ‹èªè¨€ï¼Œè«‹å…¨éƒ¨ç¿»è­¯ä¸¦æ•´ç†æˆ **ç¹é«”ä¸­æ–‡ (Traditional Chinese)**ã€‚\n"
        "2. **æ ¼å¼**ï¼š\n"
        "   - **ä¸€è¨€ä»¥è”½ä¹‹**ï¼šç”¨ä¸€å¥è©±ç¸½çµæ ¸å¿ƒä¸»æ—¨ã€‚\n"
        "   - **é—œéµé‡é»**ï¼šåˆ—å‡º 3-5 å€‹æœ€é‡è¦çš„è³‡è¨Šé» (Bullet points)ã€‚\n"
        "   - **è©³ç´°æ‘˜è¦**ï¼šé‡å°å…§å®¹é€²è¡Œé‚è¼¯åˆ†æ®µçš„è©³ç´°èªªæ˜ã€‚\n"
        "3. **èªæ°£**ï¼šå°ˆæ¥­ä½†è¼•é¬†ï¼Œé©åˆå¿«é€Ÿé–±è®€ã€‚"
        "\n\n"
        "ã€å…§å®¹ã€‘ï¼š\n{content}"
    )

    try:
        messages = []

        # === åˆ¤æ–·è¼¸å…¥ä¾†æº ===
        if state.get("file_obj"):
            # ã€æƒ…æ³ Aã€‘ï¼šæœ‰æª”æ¡ˆ (éŸ³è¨Š)
            print("æ¨¡å¼ï¼šè½è¦ºè™•ç† (Audio Processing)")
            # é€™æ˜¯ LangChain å‚³éå¤šæ¨¡æ…‹æª”æ¡ˆçš„æ¨™æº–å¯«æ³•
            message = HumanMessage(
                content=[
                    {"type": "text", "text": system_prompt},
                    {
                        "type": "media",
                        "mime_type": state["file_obj"].mime_type,
                        "data": state["file_obj"].uri,
                    },
                ]
            )
            messages = [message]

        elif state.get("content"):
            # ã€æƒ…æ³ Bã€‘ï¼šæœ‰æ–‡å­— (å­—å¹•/ç¶²é )
            print("æ¨¡å¼ï¼šæ–‡å­—é–±è®€ (Text Processing)")
            messages = [
                HumanMessage(
                    content=system_prompt + f"\n\nã€å…§å®¹ã€‘ï¼š\n{state['content']}"
                )
            ]
        else:
            return {"summary": "éŒ¯èª¤ï¼šæ²’æœ‰å…§å®¹ä¹Ÿæ²’æœ‰æª”æ¡ˆå¯ä»¥è™•ç†ã€‚"}

        # å‘¼å« AI
        response = llm.invoke(messages)

        print("æ‘˜è¦ç”Ÿæˆå®Œæˆï¼")
        return {"summary": response.content}

    except Exception as e:
        print(f"AI ç”Ÿæˆå¤±æ•—: {e}")
        return {"summary": f"AI ç”Ÿæˆå¤±æ•—: {str(e)}", "error": str(e)}


# --- 10. æ¢ä»¶é‚Šé‚è¼¯ (Router Logic) ---
def route_based_on_source(state: OmniState) -> str:
    """æ±ºå®šåˆ†æå®Œè¼¸å…¥å¾Œï¼Œè¦èµ°å“ªæ¢è·¯"""
    source = state["source_type"]
    if source == "youtube":
        return "process_youtube"
    elif source == "web":
        return "process_web"
    else:
        return "process_text"


# --- 11. çµ„è£ LangGraph ---

workflow = StateGraph(OmniState)

# (1) åŠ å…¥æ‰€æœ‰ç¯€é»
workflow.add_node("analyze_node", analyze_input_node)
workflow.add_node("youtube_node", load_youtube_node)
workflow.add_node("web_node", load_web_node)
workflow.add_node("text_node", load_text_node)
workflow.add_node("summarize_node", generate_summary_node)

# (2) è¨­å®šèµ·é»
workflow.set_entry_point("analyze_node")

# (3) è¨­å®šæ¢ä»¶é‚Š (å¾åˆ†æç¯€é»å‡ºç™¼ï¼Œåˆ†ä¸‰è·¯)
workflow.add_conditional_edges(
    "analyze_node",
    route_based_on_source,
    {
        "process_youtube": "youtube_node",
        "process_web": "web_node",
        "process_text": "text_node",
    },
)

# (4) è¨­å®šåŒ¯èšé‚Š (ä¸‰æ¢è·¯æœ€å¾Œéƒ½åŒ¯èšåˆ° æ‘˜è¦ç¯€é»)
workflow.add_edge("youtube_node", "summarize_node")
workflow.add_edge("web_node", "summarize_node")
workflow.add_edge("text_node", "summarize_node")

# (5) è¨­å®šçµ‚é»
workflow.add_edge("summarize_node", END)

# (6) ç·¨è­¯æ‡‰ç”¨ç¨‹å¼
app = workflow.compile()


# --- 12. æœ€çµ‚åŸ·è¡Œæ¸¬è©¦ ---
if __name__ == "__main__":
    print("\nğŸš€ OmniSummarizer V1 å•Ÿå‹•ï¼")

    # --- æ¸¬è©¦æ¡ˆä¾‹ ---
    # æ¡ˆä¾‹ A: ä½ çš„ YouTube å½±ç‰‡ (æ¸¬è©¦å¤šèªè¨€ç¿»è­¯èƒ½åŠ› + å­—å¹•æŠ“å–)
    input_data = "https://www.youtube.com/watch?v=M89pzPpyzpg"

    # æ¡ˆä¾‹ B: ç¶²é  (ä½ å¯ä»¥æŠŠä¸Šé¢è¨»è§£æ‰ï¼Œæ›æ¸¬é€™å€‹)
    # input_data = "https://blog.langchain.dev/langgraph-multi-agent-workflows/"

    print(f"æ­£åœ¨è™•ç†: {input_data}")

    inputs = {
        "input_text": input_data,
        "source_type": "",
        "content": None,
        "summary": None,
        "error": None,
        "file_obj": None,
    }

    try:
        # åŸ·è¡Œ LangGraph
        result = app.invoke(inputs)

        print("\n\n" + "=" * 30)
        print("ğŸŒŸ æœ€çµ‚æ‡¶äººåŒ…ç”¢å‡º ğŸŒŸ")
        print("=" * 30 + "\n")

        if result["error"]:
            print(f"âŒ ç™¼ç”ŸéŒ¯èª¤: {result['error']}")
        else:
            print(result["summary"])

    except Exception as e:
        print(f"ç¨‹å¼åŸ·è¡ŒéŒ¯èª¤: {e}")
